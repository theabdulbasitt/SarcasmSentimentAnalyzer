{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Loading dataset**\n"
      ],
      "metadata": {
        "id": "VYu3GX5KIw8X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "id": "SXK7uHfCDeOy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "61db4791-e148-404d-b596-ed7f72597287"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           urdu_text  is_sarcastic  \\\n",
              "0  ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...           1.0   \n",
              "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...           1.0   \n",
              "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...           0.0   \n",
              "3                                       Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜           0.0   \n",
              "4   `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...           1.0   \n",
              "\n",
              "   Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5 Unnamed: 6  Unnamed: 7  \n",
              "0         NaN         NaN         NaN         NaN        NaN         NaN  \n",
              "1         NaN         NaN         NaN         NaN        NaN         NaN  \n",
              "2         NaN         NaN         NaN         NaN        NaN         NaN  \n",
              "3         NaN         NaN         NaN         NaN        NaN         NaN  \n",
              "4         NaN         NaN         NaN         NaN        NaN         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-468ff26d-d068-47fa-a92a-e70278290423\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>urdu_text</th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>`` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-468ff26d-d068-47fa-a92a-e70278290423')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-468ff26d-d068-47fa-a92a-e70278290423 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-468ff26d-d068-47fa-a92a-e70278290423');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-59123cfd-a360-465e-97e1-bc6777b2df2e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-59123cfd-a360-465e-97e1-bc6777b2df2e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-59123cfd-a360-465e-97e1-bc6777b2df2e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 19955,\n  \"fields\": [\n    {\n      \"column\": \"urdu_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15813,\n        \"samples\": [\n          \"\\u0635\\u0644\\u06cc \\u0627\\u0644\\u0644\\u06c1 \\u0639\\u0644\\u06cc\\u06c1 \\u0648\\u0627\\u0670\\u0644\\u06c1 \\u0648\\u0633\\u0644\\u0645\",\n          \"\\u0633\\u0686\\u06cc \\u0645\\u0632\\u06c1 \\u0622\\u06cc\\u0627 \\u06d4\\u06d4\\u06d4\\u0648\\u06cc\\u0633\\u06d2 \\u062d\\u06cc\\u062f\\u0631 \\u0628\\u06be\\u0627\\u0626\\u06cc \\u0628\\u06c1\\u062a \\u067e\\u06cc\\u0627\\u0631\\u06d2 \\u0627\\u0646\\u0633\\u0627\\u0646 \\u06c1\\u06cc\\u06ba \\u2764\",\n          \"\\ud83d\\ude02\\ud83e\\udd23\\ud83d\\ude02\\u0622\\u067e \\u0633\\u06d2 \\u0628\\u06c1\\u062a \\u0639\\u0631\\u0635\\u06c1 \\u067e\\u06c1\\u0644\\u06d2 \\u06a9\\u06c1\\u0627 \\u062a\\u06be\\u0627 \\u06a9\\u06c1 \\u0686\\u06be\\u0648\\u0644\\u06d2 \\u0641\\u0631\\u0648\\u0634 \\u0636\\u0645\\u06cc\\u0631 \\u0641\\u0631\\u0648\\u0634 \\u0627\\u0648\\u0631 \\u0633\\u067e\\u0644\\u0627\\u0626\\u06cc\\u0631 \\u062e\\u0648\\u062f \\u0633\\u0627\\u062e\\u062a\\u06c1 \\u0635\\u062d\\u0627\\u0641\\u06cc \\u06c1\\u06d2 \\u06cc\\u06c1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_sarcastic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5000119253068598,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 6\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.506009406240056,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('urdu_sarcastic_dataset.csv')\n",
        "\n",
        "# Dropping null values in the 'urdu_text' column\n",
        "df.dropna(subset=['urdu_text'], inplace=True)\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing stopwords and extra spacing"
      ],
      "metadata": {
        "id": "w9z8WNz-Y8rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop words\n",
        "stopwords = [\n",
        "    'Ø§ÙˆØ±', 'Ú©ÛŒ', 'ÛÛ’', 'Ù…ÛŒÚº', 'Ú©Ùˆ', 'Ú©Û’', 'ØªÚ¾Ø§', 'ØªÚ¾Û’', 'ØªÚ¾ÛŒ', 'Ù¾Ø±',\n",
        "    'ÛÙˆ', 'Ú©Ø§', 'Ù†ÛÛŒÚº', 'Ø¨Ú¾ÛŒ', 'Ø¬Ùˆ', 'ÙˆÛ', 'ÛŒÛ', 'Ø§ÛŒÚ©', 'Ø§Ú¯Ø±',\n",
        "    'ØªÚ©', 'Ù„ÛŒÚ©Ù†', 'ÛÙ…', 'ØªÙ…', 'Ø§Ø³', 'Ø§Ù†', 'Ø§Ù¾Ù†Û’', 'ÛÙ…ÛŒÚº', 'Ù…ÛŒØ±Û’',\n",
        "    'Ù¾Ø§Ø³', 'Ø³Ø¨', 'ÙˆÛØ§Úº', 'Ø¬Ø³', 'ØµØ±Ù', 'ØªØ¬Ú¾Û’', 'Ú†ÙˆÙ†Ú©Û', 'ØªØ§Ú©Û',\n",
        "    'Ú©Ú†Ú¾', 'ØªÚ¾Ø§', 'ØªÙˆ', 'Ø¯Ùˆ', 'Ø³Ø§ØªÚ¾', 'Ú©ÛŒÙˆÚº', 'Ù¾Ú¾Ø±', 'Ø§Ú¯Ø±',\n",
        "    'Ø¬Ø¨', 'Ø¬ÛØ§Úº', 'Ø§ÛŒØ³Ø§', 'Ú©Ø³ÛŒ', 'Ú©Ø³', 'Ø§Ù†Ú©Ø§', 'Ø§Ù¾Ù†Ø§', 'Ø§Ù†Ú©Û’',\n",
        "    'ÛŒÛØ§Úº', 'Ú©ÛŒØ§', 'Ù†Û', 'Ù¾ÛÙ„Û’', 'Ø¨Ø¹Ø¯', 'Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ', 'ÛÙˆØ§',\n",
        "    'Ø¯ÙˆØ±', 'Ø¬ÛØ§Úº', 'Ú©Ù…', 'Ø²ÛŒØ§Ø¯Û', 'Ø¯ÙˆØ³Ø±Û’', 'Ø¬ÛŒØ³Û’', 'Ú†Ø§ÛÛŒÛ’',\n",
        "    'Ø¨ØºÛŒØ±', 'Ø³ÙˆØ§Ù„', 'Ø¬ÙˆØ§Ø¨', 'ØªØ§Ú©Û', 'Ø®ÙˆØ¯', 'Ø§Ù¾Ù†Û’', 'Ú©ÛŒØ§'\n",
        "]\n",
        "\n",
        "\n",
        "# Function to remove stop words\n",
        "def removing_stopwords(text):\n",
        "    if isinstance(text, str):  # Checking for exceptions\n",
        "        words = text.split()\n",
        "        clean_words = [word for word in words if word not in stopwords]\n",
        "        return ' '.join(clean_words)\n",
        "    return text\n",
        "\n",
        "# Applying stopword removal\n",
        "df['cleaned_text'] = df['urdu_text'].apply(removing_stopwords)\n",
        "\n",
        "\n",
        "\n",
        "# Display the cleaned text\n",
        "print(df[['urdu_text', 'cleaned_text']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo_B09pMY88t",
        "outputId": "b6e149fe-3cf8-4e00-f752-4f59124b086f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           urdu_text  \\\n",
            "0  ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...   \n",
            "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...   \n",
            "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...   \n",
            "3                                       Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜   \n",
            "4   `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0         ğŸ¤£ğŸ˜‚ğŸ˜‚ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© Ú©ÙˆØ¬ÛŒ ğŸ˜ğŸ˜ğŸ˜ğŸ¤£  \n",
            "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø¢Úº ...  \n",
            "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...  \n",
            "3                                            Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜  \n",
            "4  `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ '' Ø­Ø§Ù…Ø¯...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing emojis, Hashtag and URLS\n"
      ],
      "metadata": {
        "id": "Ke2321x4ZM4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Emoji dictionary for sentiment mapping\n",
        "emoji_sentiment_dict = {\n",
        "    \"ğŸ˜Š\": \"positive\",\n",
        "    \"ğŸ˜\": \"positive\",\n",
        "    \"ğŸ˜‚\": \"positive\",\n",
        "    \"ğŸ˜¢\": \"negative\",\n",
        "    \"ğŸ˜¡\": \"negative\",\n",
        "    \"ğŸ˜\": \"positive\",\n",
        "    \"ğŸ˜”\": \"negative\"\n",
        "}\n",
        "\n",
        "# Function to clean the text\n",
        "def clean_text(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    # Remove hashtags\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Translate emojis using the emoji sentiment dictionary\n",
        "    for emoji, sentiment in emoji_sentiment_dict.items():\n",
        "        text = text.replace(emoji, sentiment)\n",
        "    return text\n",
        "\n",
        "# Apply cleaning to the text\n",
        "df['cleaned_text'] = df['urdu_text'].apply(clean_text)\n",
        "\n",
        "# Display cleaned text\n",
        "print(df[['urdu_text', 'cleaned_text']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfB1a1SPZNiq",
        "outputId": "7efd009a-7c72-4da7-ba12-3a99beae372a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           urdu_text  \\\n",
            "0  ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...   \n",
            "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...   \n",
            "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...   \n",
            "3                                       Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜   \n",
            "4   `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0   ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†ÛÛŒÚº ...  \n",
            "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...  \n",
            "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...  \n",
            "3                                        Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ†   \n",
            "4    Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ Øª...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Filtering Short Conversations**"
      ],
      "metadata": {
        "id": "g4ta0i3oFh1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to filter out posts with fewer than three words\n",
        "def filter_short_posts(text):\n",
        "    # Split the text into words and count the words\n",
        "    word_count = len(text.split())\n",
        "    # Keep the post only if it has 3 or more words\n",
        "    if word_count >= 3:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Filter out short posts\n",
        "df = df[df['cleaned_text'].apply(filter_short_posts)]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WDE0Yi8cFjMk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Applying  and stemming**"
      ],
      "metadata": {
        "id": "wtlemv6RcmJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform basic stemming\n",
        "def simple_stem(word):\n",
        "    # List of common Urdu suffixes\n",
        "    suffixes = ['ÛŒÚº', 'ÙˆÚº', 'Û’', 'Ù†Û’', 'Ø§', 'ÛŒ', 'Øª', 'Ù†Ø§', 'Ú¯Ø§', 'Ú¯ÛŒ', 'ØªÛ’', 'Ù„', 'ÙˆÚº', 'ØªØ§', 'ØªÛ’', 'Ø§Ø³', 'Ú©Ø§']\n",
        "\n",
        "    # Remove suffixes from the word\n",
        "    for suffix in suffixes:\n",
        "        if word.endswith(suffix):\n",
        "            return word[:-len(suffix)]\n",
        "\n",
        "    return word  #return word if no suffix\n",
        "\n",
        "# Function for stemming the entire text\n",
        "def stem_text(text):\n",
        "    stemmed_words = [simple_stem(word) for word in text.split()]\n",
        "    return ' '.join(stemmed_words)\n",
        "\n",
        "# Apply stemming to the cleaned text\n",
        "df['stemmed_text'] = df['cleaned_text'].apply(stem_text)\n",
        "\n",
        "# Display the cleaned and stemmed text\n",
        "print(df[['cleaned_text', 'stemmed_text']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZADq18oPbt8P",
        "outputId": "c907e7d3-a0eb-41ff-c9f4-6e1aa886f6ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        cleaned_text  \\\n",
            "0                 Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© Ú©ÙˆØ¬ÛŒ    \n",
            "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø¢Úº Ù…ÛŒÚº   \n",
            "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...   \n",
            "3                                             Ù¾Ø§Ø¦ÛŒÙ†    \n",
            "4      Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ  Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±   \n",
            "\n",
            "                                        stemmed_text  \n",
            "0                       Ù„ÛŒÙ† Ø¯ Ù…ÛŒØ± Ø´Ø§Ø¯ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© Ú©ÙˆØ¬  \n",
            "1             Ú† Ù…ÛÙ…Ø§Ù† Ú©Ú¾Ø§Ù† Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒ Ú†Ø§Ú† Ù† Ø¯Ø³Ø¯ Ø¢Úº Ù…  \n",
            "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú© Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø± Ù„Ú¯Ø§Ø¦ Ú¯Ø¦ Ø§Ù¾ÙˆØ²ÛŒØ´...  \n",
            "3                                              Ù¾Ø§Ø¦ÛŒÙ†  \n",
            "4            Ù…Ø±Ø§Ø¯ Ø¹Ù„ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ Úˆ Ø¬ Ø¢Ø¦ Ø§ÛŒØ³ Ø¢Ø¦ Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Applying lematization**"
      ],
      "metadata": {
        "id": "fccxNkdgHOHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple lemmatization dictionary\n",
        "lemmatization_dict = {\n",
        "    'Ú©Ø±': 'Ú©Ø±Ù†Ø§',\n",
        "    'Ø¬Ø§ØªÛŒ': 'Ø¬Ø§Ù†Ø§Û',\n",
        "    'Ú¯ÛŒØ§': 'Ø¬Ø§Ù†Ø§Û',\n",
        "    'Ú©ÛŒØ§': 'Ú©Ø±Ù†Ø§',\n",
        "    'ØªÚ¾Ø§': 'ÛÙˆÙ†Ø§',\n",
        "    'ÛÙˆÚº': 'ÛÙˆÙ†Ø§',\n",
        "    'ÛÛŒÚº': 'ÛÙˆÙ†Ø§',\n",
        "    'ØªÚ¾ÛŒ': 'ÛÙˆÙ†Ø§',\n",
        "    'Ú†Ù„Û’': 'Ú†Ù„Ù†Ø§',\n",
        "    'Ú†Ù„ÛŒ': 'Ú†Ù„Ù†Ø§',\n",
        "    'Ø¯Û’': 'Ø¯ÛŒÙ†Ø§',\n",
        "    'Ù„Ú©Ú¾Ø§': 'Ù„Ú©Ú¾Ù†Ø§',\n",
        "    'Ø¯ÛŒÚ©Ú¾Ø§': 'Ø¯ÛŒÚ©Ú¾Ù†Ø§',\n",
        "\n",
        "}\n",
        "\n",
        "# Function for basic lemmatization\n",
        "def lemmatize_word(word):\n",
        "    return lemmatization_dict.get(word, word)  # Return the lemma or the original word\n",
        "\n",
        "# Function for lemmatizing the entire text\n",
        "def lemmatize_text(text):\n",
        "    lemmatized_words = [lemmatize_word(word) for word in text.split()]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Applying lemmatization to the cleaned text\n",
        "df['lemmatized_text'] = df['cleaned_text'].apply(lemmatize_text)\n",
        "\n",
        "# Display the cleaned and lemmatized text\n",
        "print(df[['cleaned_text', 'lemmatized_text']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fTov9OCmj61",
        "outputId": "2dd69f70-5340-4917-c77a-f1f17a334ecc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        cleaned_text  \\\n",
            "0                 Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© Ú©ÙˆØ¬ÛŒ    \n",
            "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø¢Úº Ù…ÛŒÚº   \n",
            "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...   \n",
            "3                                             Ù¾Ø§Ø¦ÛŒÙ†    \n",
            "4      Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ  Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±   \n",
            "\n",
            "                                     lemmatized_text  \n",
            "0                Ù„ÛŒÙ†Û’ Ø¯ÛŒÙ†Ø§ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© Ú©ÙˆØ¬ÛŒ  \n",
            "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø±Ù†Ø§ Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ Ø¢...  \n",
            "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...  \n",
            "3                                              Ù¾Ø§Ø¦ÛŒÙ†  \n",
            "4       Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ø¨Ú¾ÛŒØ³ ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ Ø­Ø§Ù…Ø¯ Ù…ÛŒØ±  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization**"
      ],
      "metadata": {
        "id": "prlhHpFrBaGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for manual tokenization (as before)\n",
        "def manual_tokenizer(text):\n",
        "    tokens = re.findall(r'\\S+', text)  # Split by whitespace, preserving words\n",
        "    return tokens\n",
        "\n",
        "# Tokenize the lemmatized text\n",
        "df['tokens'] = df['lemmatized_text'].apply(manual_tokenizer)\n",
        "\n",
        "# Display the tokenized version of several Urdu social media posts\n",
        "print(df[['urdu_text', 'tokens']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZbTPPA5Bajf",
        "outputId": "b6d1a47a-f745-4211-9dda-0bc84a3d58a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           urdu_text  \\\n",
            "0  ğŸ¤£ğŸ˜‚ğŸ˜‚ ÛÙˆ Ù„ÛŒÙ†Û’ Ø¯Û’ Ù…ÛŒØ±ÛŒ Ø´Ø§Ø¯ÛŒ ÙØ³Ø§Ø¯Ù† Ù¹Ú¾ÛŒÚ© ÛÛ’ Ú©ÙˆØ¬ÛŒ Ù†Û...   \n",
            "1  Ú†Ù„ Ù…ÛÙ…Ø§Ù†ÙˆÚº Ù…ÛŒÚº Ú©Ú¾Ø§Ù†Ø§ Ø³Ø±Ùˆ Ú©Ø± Ú†Ú‘ÛŒÙ„ Ú†Ø§Ú†ÛŒ Ù†ÙˆÚº Ø¯Ø³Ø¯ÛŒ...   \n",
            "2  Ú©Ø§Ù…Ø±Ø§Ù† Ø®Ø§Ù† Ø¢Ù¾Ú©ÛŒ Ø¯Ù† Ø¨Ú¾Ø±ÛŒÛ Ø²Ù…Û Ø¯Ø§Ø±ÛŒ Ù„Ú¯Ø§Ø¦ÛŒ Ú¯Ø¦ÛŒ Ø§Ù¾...   \n",
            "3                                       Ù†ÛÛŒÚº Ù¾Ø§Ø¦ÛŒÙ† ğŸ˜   \n",
            "4   `` Ù…Ø±Ø§Ø¯ Ø¹Ù„ÛŒ Ø´Ø§Û Ú©Û’ Ø¨Ú¾ÛŒØ³ Ù…ÛŒÚº ÚˆÛŒ Ø¬ÛŒ Ø¢Ø¦ÛŒ Ø§ÛŒØ³ Ø¢Ø¦ÛŒ...   \n",
            "\n",
            "                                              tokens  \n",
            "0        [Ù„ÛŒÙ†Û’, Ø¯ÛŒÙ†Ø§, Ù…ÛŒØ±ÛŒ, Ø´Ø§Ø¯ÛŒ, ÙØ³Ø§Ø¯Ù†, Ù¹Ú¾ÛŒÚ©, Ú©ÙˆØ¬ÛŒ]  \n",
            "1  [Ú†Ù„, Ù…ÛÙ…Ø§Ù†ÙˆÚº, Ú©Ú¾Ø§Ù†Ø§, Ø³Ø±Ùˆ, Ú©Ø±Ù†Ø§, Ú†Ú‘ÛŒÙ„, Ú†Ø§Ú†ÛŒ, Ù†Ùˆ...  \n",
            "2  [Ú©Ø§Ù…Ø±Ø§Ù†, Ø®Ø§Ù†, Ø¢Ù¾Ú©ÛŒ, Ø¯Ù†, Ø¨Ú¾Ø±ÛŒÛ, Ø²Ù…Û, Ø¯Ø§Ø±ÛŒ, Ù„Ú¯Ø§Ø¦...  \n",
            "3                                            [Ù¾Ø§Ø¦ÛŒÙ†]  \n",
            "4  [Ù…Ø±Ø§Ø¯, Ø¹Ù„ÛŒ, Ø´Ø§Û, Ø¨Ú¾ÛŒØ³, ÚˆÛŒ, Ø¬ÛŒ, Ø¢Ø¦ÛŒ, Ø§ÛŒØ³, Ø¢Ø¦ÛŒ, ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TF-IDF**"
      ],
      "metadata": {
        "id": "dQLFfTtoNgb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Join tokens back into strings for each row to prepare for TF-IDF\n",
        "df['tokens_joined'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(max_features=1000, min_df=1, max_df=0.95)\n",
        "\n",
        "# Apply TF-IDF to the joined tokens\n",
        "tfidf_matrix = tfidf.fit_transform(df['tokens_joined'])\n",
        "\n",
        "# Convert the TF-IDF matrix to a DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
        "\n",
        "# Get the top 10 words with the highest TF-IDF scores\n",
        "top_tfidf_words = tfidf_df.sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "# Display the top 10 words\n",
        "print(\"Top 10 words with the highest TF-IDF scores:\")\n",
        "print(top_tfidf_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9fyZKpO3tzq",
        "outputId": "04629e42-3ae5-411f-c9d4-e8f5cc208d5a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 words with the highest TF-IDF scores:\n",
            "ÛÙˆÙ†Ø§     886.323177\n",
            "Ø³Û’       786.088821\n",
            "Ú©Ø±Ù†Ø§     608.484694\n",
            "Ù†Û’       582.377779\n",
            "ÛÛŒ       457.097862\n",
            "Ø¢Ù¾       432.586687\n",
            "ÛÛ’       420.659056\n",
            "Ú©Û       409.497448\n",
            "Ø§Ù„Ù„Û     328.875276\n",
            "Ø¬Ø§Ù†Ø§Û    282.683598\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word2vec**"
      ],
      "metadata": {
        "id": "JPsfjv6ZB8TH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Prepare the tokenized data as input for Word2Vec\n",
        "tokenized_texts = df['tokens'].tolist()\n",
        "\n",
        "# Train a Word2Vec model (adjust parameters as necessary)\n",
        "model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Get the top 5 most similar words to 'Ø§Ú†Ú¾Ø§'\n",
        "similar_words = model.wv.most_similar('Ø§Ú†Ú¾Ø§', topn=5)\n",
        "\n",
        "# Display the top 5 similar words\n",
        "print(\"Top 5 words most similar to 'Ø§Ú†Ú¾Ø§':\")\n",
        "for word, similarity in similar_words:\n",
        "    print(f\"{word}: {similarity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyS1G8WGB9Cq",
        "outputId": "5e94803a-63db-406b-b5e1-ab8ced5493c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 words most similar to 'Ø§Ú†Ú¾Ø§':\n",
            "Ù…Ø²Ø§Ù‚: 0.989402711391449\n",
            "Ø¨Ú‘ÛŒ: 0.9893449544906616\n",
            "Ø¢Ø³Ø§Ù†: 0.9883087873458862\n",
            "ØµØ­ÛŒØ­: 0.987295389175415\n",
            "Ú†Ø§ÛØªØ§: 0.9872193336486816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NGRAMS**"
      ],
      "metadata": {
        "id": "Kf2MiU3BCo8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.util import ngrams\n",
        "\n",
        "# Function to generate unigrams, bigrams, and trigrams\n",
        "def generate_ngrams(tokens_list, n):\n",
        "    n_grams = [ngrams(tokens, n) for tokens in tokens_list]\n",
        "    return [gram for grams in n_grams for gram in grams]  # Flatten the list\n",
        "\n",
        "# Generate unigrams, bigrams, and trigrams\n",
        "unigrams = generate_ngrams(df['tokens'].tolist(), 1)\n",
        "bigrams = generate_ngrams(df['tokens'].tolist(), 2)\n",
        "trigrams = generate_ngrams(df['tokens'].tolist(), 3)\n",
        "\n",
        "# Count frequencies of bigrams and trigrams\n",
        "bigram_freq = Counter(bigrams)\n",
        "trigram_freq = Counter(trigrams)\n",
        "\n",
        "# Get the top 10 most common bigrams and trigrams\n",
        "top_10_bigrams = bigram_freq.most_common(10)\n",
        "top_10_trigrams = trigram_freq.most_common(10)\n",
        "\n",
        "# Display top 10 bigrams\n",
        "print(\"Top 10 most common bigrams:\")\n",
        "for bigram, freq in top_10_bigrams:\n",
        "    print(f\"{bigram}: {freq}\")\n",
        "\n",
        "# Display top 10 trigrams\n",
        "print(\"\\nTop 10 most common trigrams:\")\n",
        "for trigram, freq in top_10_trigrams:\n",
        "    print(f\"{trigram}: {freq}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxnE3XjgCr4h",
        "outputId": "ca640200-e614-4e59-8bd3-bbe2c5ca38a6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 most common bigrams:\n",
            "('Ø¹Ù…Ø±Ø§Ù†', 'Ø®Ø§Ù†'): 500\n",
            "('Ù†ÙˆØ§Ø²', 'Ø´Ø±ÛŒÙ'): 446\n",
            "('Ø±ÛÛ’', 'ÛÙˆÙ†Ø§'): 435\n",
            "('Ø¢Ø¦ÛŒ', 'Ø¬ÛŒ'): 312\n",
            "('Ø³Ù†Ø¯Ú¾', 'Ù¾ÙˆÙ„ÛŒØ³'): 297\n",
            "('Ú©ÛØªÛ’', 'ÛÙˆÙ†Ø§'): 250\n",
            "('Ú©Ø±ØªÛ’', 'ÛÙˆÙ†Ø§'): 246\n",
            "('Ø¢Ø±Ù…ÛŒ', 'Ú†ÛŒÙ'): 223\n",
            "('Ø¢Ù¾', 'Ù†Û’'): 221\n",
            "('Ø¬Ø²Ø§Ú©', 'Ø§Ù„Ù„Û'): 209\n",
            "\n",
            "Top 10 most common trigrams:\n",
            "('Ø¢Ø¦ÛŒ', 'Ø¬ÛŒ', 'Ø³Ù†Ø¯Ú¾'): 118\n",
            "('Ù¾ÛŒ', 'Ù¹ÛŒ', 'Ø¢Ø¦ÛŒ'): 114\n",
            "('Ú©Ø±Ù†Ø§', 'Ø±ÛÛ’', 'ÛÙˆÙ†Ø§'): 111\n",
            "('ØµÙ„ÛŒ', 'Ø§Ù„Ù„Û', 'Ø¹Ù„ÛŒÛ'): 108\n",
            "('Ø§Ù„Ù„Û', 'Ø¹Ù„ÛŒÛ', 'ÙˆØ¢Ù„Û'): 87\n",
            "('Ø¹Ù„ÛŒÛ', 'ÙˆØ¢Ù„Û', 'ÙˆØ³Ù„Ù…'): 87\n",
            "('Ù¾ÛŒ', 'ÚˆÛŒ', 'Ø§ÛŒÙ…'): 86\n",
            "('Ø¬Ø²Ø§Ú©', 'Ø§Ù„Ù„Û', 'Ø®ÛŒØ±'): 78\n",
            "('ÙØ§Ù„Ùˆ', 'Ú©Ø±ÛŒÚº', 'ÙØ§Ù„Ùˆ'): 73\n",
            "('Ú©Ø±ÛŒÚº', 'ÙØ§Ù„Ùˆ', 'Ø¨ÛŒÚ©'): 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification Model**"
      ],
      "metadata": {
        "id": "nihvjF4DDHOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Assuming 'sentiment' column exists in your dataset (1 for positive, 0 for negative)\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, df['is_sarcastic'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model (you can switch to SVM, Naive Bayes, etc.)\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict sentiment on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Print detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V74ZL5_CDL-H",
        "outputId": "2a49d1e7-6d50-495c-ddfb-12aef9c2d507"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7685\n",
            "Precision: 0.7643\n",
            "Recall: 0.7572\n",
            "F1-score: 0.7607\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.77      0.78      0.78      2051\n",
            "         1.0       0.76      0.76      0.76      1940\n",
            "\n",
            "    accuracy                           0.77      3991\n",
            "   macro avg       0.77      0.77      0.77      3991\n",
            "weighted avg       0.77      0.77      0.77      3991\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation and Optimization**"
      ],
      "metadata": {
        "id": "pPr12vJuNlKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Splitting data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(tfidf_matrix, df['is_sarcastic'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_val_pred = model.predict(X_val)\n",
        "\n",
        "# Generate classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "# Generate confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_val_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXvfAQB8-fxn",
        "outputId": "e82bfc6f-e0dc-49ec-a6ef-6ae96215a5bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.77      0.78      0.78      2051\n",
            "         1.0       0.76      0.76      0.76      1940\n",
            "\n",
            "    accuracy                           0.77      3991\n",
            "   macro avg       0.77      0.77      0.77      3991\n",
            "weighted avg       0.77      0.77      0.77      3991\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1598  453]\n",
            " [ 471 1469]]\n"
          ]
        }
      ]
    }
  ]
}